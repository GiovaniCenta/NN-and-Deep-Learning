{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86cacc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a logistic regression model that will predict if a cat is on the image or not.\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "#sigmoid function for later use\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c17661fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - first step, loading the dataset\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) \n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) \n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) \n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) \n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) \n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "#load variables\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69f72ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 - initialize w's and b's with 0\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0.0\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81c5fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.1 -  We can also standize our set\n",
    "\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = 64\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "\n",
    "train_set_x = train_set_x_flatten / 255.\n",
    "test_set_x = test_set_x_flatten / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6ac7d",
   "metadata": {},
   "source": [
    "\n",
    "Now we can use forward propagation to calcute the cost and compute A, after that we can use backwards propagation to minimize the errors .\n",
    "\n",
    "we forward propagate to get the output and compare it with the real value to get the error.\n",
    "\n",
    "To minimize the error, you propagate backwards by finding the derivative of error with respect to each weight and then subtracting this value from the weight value.\n",
    "\n",
    "\n",
    "Forward Propagation:\n",
    "- You compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)}))$\n",
    "\n",
    "backwards propagation: \n",
    "\n",
    "$$ - \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ - \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "919292bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 - Cost function and activators vector\n",
    "def propagate(w, b, X, Y):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X) + b)\n",
    "    \n",
    "    \n",
    "    cost = -1/m * (np.dot(Y,np.log(A).T) + np.dot((1-Y),np.log(1 - A).T))   \n",
    "    \n",
    "    \n",
    "   \n",
    "                          \n",
    "    dw=(1/m)*np.dot(X,(A-Y).T)\n",
    "    db=(1/m)*np.sum(A-Y)\n",
    "    \n",
    "    \n",
    "    cost = np.squeeze(np.array(cost))\n",
    "\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "434488cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 - Optimize the parameters w and b with a gradient descent algorithm, the goal is to minimize the cost function\n",
    "#but for this we need to propagate, to compute the cost function first\n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n",
    "    \n",
    "    \n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "       \n",
    "        grads, cost = propagate(w,b,X,Y) #we use propagate to do this to every w and b\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        \n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d6dfa",
   "metadata": {},
   "source": [
    "Now we will predict Y.\n",
    "\n",
    "Calculate $$ ð‘ŒÌ‚ =ð´=ðœŽ(ð‘¤ð‘‡ð‘‹+ð‘) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "248baa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 - Predict A(Y)\n",
    "def predict(w, b, X):\n",
    "   \n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        \n",
    "        if A[0, i] > 0.5 :\n",
    "             Y_prediction[0,i] = 1\n",
    "        else:\n",
    "             Y_prediction[0,i] = 0\n",
    "        \n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "03d884c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (Temp/ipykernel_524/3501385704.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_524/3501385704.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate, print_cost = False):\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "#6 -  method to call all methods above\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, print_cost = False,learning_rate):\n",
    "    \n",
    "    w, b = initialize_with_zeros(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent \n",
    "    parameters, grads, costs =  optimize(w, b, X_train, Y_train, num_iterations= 2000, learning_rate = 0.5, print_cost = False)\n",
    "    \n",
    "    # Retrieve parameters w and b \n",
    "    w = parameters[\"w\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples \n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "\n",
    "   \n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "19d110dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_524/2531435041.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -1/m * (np.dot(Y,np.log(A).T) + np.dot((1-Y),np.log(1 - A).T))\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_524/692102586.py:13: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 100.0 %\n",
      "test accuracy: 74.0 %\n"
     ]
    }
   ],
   "source": [
    "#7 - Finally, training the model\n",
    "logistic_regression_model = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.001, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8c0c1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXTRA - plotting curves\n",
    "costs = np.squeeze(logistic_regression_model['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(logistic_regression_model[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b736ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
